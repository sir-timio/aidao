{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os, numpy as np\n",
    "    import torch\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1337) # leet :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "from enum import Enum\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import typing as t\n",
    "\n",
    "# import cv2\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as td\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import pytorch_lightning as pl\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from torchmetrics.functional import auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    show_photos, \n",
    "    create_dataloader,\n",
    "    train_epoch,\n",
    "    test_epoch,\n",
    "    plot_history,\n",
    "    print_model_params_required_grad,\n",
    "    PUBLIC_DATA_FOLDER_PATH,\n",
    "    PUBLIC_DATA_DESCRIPTION_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Yandex GO is one of the top three ride-hailing services in the world. Our app facilitates over 4 billion trips per year across 32 countries. We are committed to the quality of our services, ensuring thorough checks of both drivers and their vehicles before they go online, based on dozens of criteria. Part of the vehicle inspection process is carried out remotely using photos of the vehicle, which allows us to either block or grant the driver access to orders. This tool ensures that cars do not go online if they are damaged or dirty.\n",
    "\n",
    "Computer vision algorithms play a significant role in this remote quality control process. Machine learning models act as a filter that processes vehicle inspection requests, automatically approving a portion of requests that, according to the models, contain no violations, and sending suspicious cases for additional manual review.\n",
    "\n",
    "### How does the photo inspection process work?\n",
    "As part of vehicle photo inspections, drivers periodically receive a task to take photos of their car, so it can be checked for damage, compliance with service standards, branding presence, etc. Before these checks, we also need to ensure that drivers took the photos honestly and sent what we expected. The driver is required to take 4 photos (front, rear, left side, right side). The photos are taken through the Yandex PRO app, which has an interface that guides them to capture the 4 photos in the correct order and from the required angles.\n",
    "\n",
    "In the standard process, the photos are first reviewed by ML pipeline. If ML pipeline doesn't find anything suspicious in the photos, the inspection is automatically approved. If the pipeline flags at least one photo, the inspection is sent to an assessor for a final decision. Thus, the object for decision-making is the inspection itself, i.e., all 4 photos together.\n",
    "\n",
    "In this task, the license plate numbers have been blacked out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_id = '000f43a6549ad26d'\n",
    "photos = []\n",
    "for side in ['front', 'back', 'left', 'right']:\n",
    "    with open(f'{PUBLIC_DATA_FOLDER_PATH}/{pass_id}_{side}', 'rb') as file:\n",
    "        photos.append(file.read())\n",
    "show_photos(photos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description: \n",
    "- **filename** —  name of the photo file, consisting of `pass_id` and `plan_side`.\n",
    "- **pass_id** — ID of the inspection. Each inspection contains 4 photos.\n",
    "- **plan_side** — the side of the vehicle that should be in the photo. Possible values: front, back, left, right.\n",
    "- **fact_side** — the side of the vehicle as determined by assessors. Possible values: front, back, left, right, unknown.\n",
    "- **fraud_verdict** — the assessor's verdict on what is depicted in the photo. Possible values:\n",
    "   - ALL_GOOD —  the photo clearly shows one side of the vehicle, which is fully visible and in focus.\n",
    "   - LACK_OF_PHOTOS — the photo does not contain a vehicle at all.\n",
    "   - BLURRY_PHOTO — the photo is blurry.\n",
    "   - SCREEN_PHOTO — not a real vehicle photo, but a photo of a screen.\n",
    "   - DARK_PHOTO — the photo is too dark.\n",
    "   - INCOMPLETE_CAPTURE — the vehicle is not fully visible in the photo.\n",
    "- **fraud_probability** — the proportion of assessors who assigned the given fraud_verdict. If no verdict achieved a majority, a random one is chosen.\n",
    "- **damage_verdict** — the assessor's verdict on the vehicle's condition. Possible values:\n",
    "   - NO_DEFECT —  no visible damage.\n",
    "   - DEFECT — the is some damage.\n",
    "   - BAD_PHOTO — can't say anything about the damage, because of photo's quality.\n",
    "- **damage_probability** — the proportion of assessors who assigned the given damage_verdict. If no verdict achieved a majority, a random one is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pass_id</th>\n",
       "      <th>plan_side</th>\n",
       "      <th>fact_side</th>\n",
       "      <th>fraud_verdict</th>\n",
       "      <th>fraud_probability</th>\n",
       "      <th>damage_verdict</th>\n",
       "      <th>damage_probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00015b960a1c013e_back</th>\n",
       "      <td>00015b960a1c013e</td>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "      <td>DARK_PHOTO</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>BAD_PHOTO</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00015b960a1c013e_front</th>\n",
       "      <td>00015b960a1c013e</td>\n",
       "      <td>front</td>\n",
       "      <td>front</td>\n",
       "      <td>DARK_PHOTO</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>BAD_PHOTO</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00015b960a1c013e_left</th>\n",
       "      <td>00015b960a1c013e</td>\n",
       "      <td>left</td>\n",
       "      <td>unknown</td>\n",
       "      <td>DARK_PHOTO</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>BAD_PHOTO</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00015b960a1c013e_right</th>\n",
       "      <td>00015b960a1c013e</td>\n",
       "      <td>right</td>\n",
       "      <td>unknown</td>\n",
       "      <td>DARK_PHOTO</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>BAD_PHOTO</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001f673ef360c58_back</th>\n",
       "      <td>0001f673ef360c58</td>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "      <td>ALL_GOOD</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NO_DEFECT</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 pass_id plan_side fact_side fraud_verdict  \\\n",
       "filename                                                                     \n",
       "00015b960a1c013e_back   00015b960a1c013e      back      back    DARK_PHOTO   \n",
       "00015b960a1c013e_front  00015b960a1c013e     front     front    DARK_PHOTO   \n",
       "00015b960a1c013e_left   00015b960a1c013e      left   unknown    DARK_PHOTO   \n",
       "00015b960a1c013e_right  00015b960a1c013e     right   unknown    DARK_PHOTO   \n",
       "0001f673ef360c58_back   0001f673ef360c58      back      back      ALL_GOOD   \n",
       "\n",
       "                        fraud_probability damage_verdict  damage_probability  \n",
       "filename                                                                      \n",
       "00015b960a1c013e_back            1.000000      BAD_PHOTO                 0.8  \n",
       "00015b960a1c013e_front           0.666667      BAD_PHOTO                 1.0  \n",
       "00015b960a1c013e_left            0.666667      BAD_PHOTO                 0.6  \n",
       "00015b960a1c013e_right           0.666667      BAD_PHOTO                 1.0  \n",
       "0001f673ef360c58_back            0.666667      NO_DEFECT                 1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = pd.read_csv(PUBLIC_DATA_DESCRIPTION_PATH, index_col='filename').sort_index()\n",
    "description.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to fraud that can be identified by looking at an individual photo, there may be cases where each photo individually has a fraud_verdict of 'ALL_GOOD', but the driver took two photos of the same side of the vehicle and failed to capture another side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pass_id</th>\n",
       "      <th>plan_side</th>\n",
       "      <th>fact_side</th>\n",
       "      <th>fraud_verdict</th>\n",
       "      <th>fraud_probability</th>\n",
       "      <th>damage_verdict</th>\n",
       "      <th>damage_probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001c07aa1e3edf7e_back</th>\n",
       "      <td>001c07aa1e3edf7e</td>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "      <td>ALL_GOOD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_DEFECT</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001c07aa1e3edf7e_front</th>\n",
       "      <td>001c07aa1e3edf7e</td>\n",
       "      <td>front</td>\n",
       "      <td>front</td>\n",
       "      <td>ALL_GOOD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_DEFECT</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001c07aa1e3edf7e_left</th>\n",
       "      <td>001c07aa1e3edf7e</td>\n",
       "      <td>left</td>\n",
       "      <td>front</td>\n",
       "      <td>ALL_GOOD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_DEFECT</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001c07aa1e3edf7e_right</th>\n",
       "      <td>001c07aa1e3edf7e</td>\n",
       "      <td>right</td>\n",
       "      <td>back</td>\n",
       "      <td>ALL_GOOD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_DEFECT</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 pass_id plan_side fact_side fraud_verdict  \\\n",
       "filename                                                                     \n",
       "001c07aa1e3edf7e_back   001c07aa1e3edf7e      back      back      ALL_GOOD   \n",
       "001c07aa1e3edf7e_front  001c07aa1e3edf7e     front     front      ALL_GOOD   \n",
       "001c07aa1e3edf7e_left   001c07aa1e3edf7e      left     front      ALL_GOOD   \n",
       "001c07aa1e3edf7e_right  001c07aa1e3edf7e     right      back      ALL_GOOD   \n",
       "\n",
       "                        fraud_probability damage_verdict  damage_probability  \n",
       "filename                                                                      \n",
       "001c07aa1e3edf7e_back                 1.0      NO_DEFECT                 1.0  \n",
       "001c07aa1e3edf7e_front                1.0      NO_DEFECT                 1.0  \n",
       "001c07aa1e3edf7e_left                 1.0      NO_DEFECT                 1.0  \n",
       "001c07aa1e3edf7e_right                1.0      NO_DEFECT                 0.8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description[description.pass_id == '001c07aa1e3edf7e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "To assess the quality of vehicles and photos using machine learning algorithms:  \n",
    "1. For detecting fraud (incorrect photos, unclear images, or incorrect photo sets).  \n",
    "2. For detecting vehicle damage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metric and Deliverables\n",
    "There are 2 targets and 4 sides of a vehicle in each exam. But after all, we need to predict whether the inspection should be sent to a human for review to provide feedback to the driver, or if there are no defects and the inspection can be automatically approved. This means that the metric is calculated not for individual photos for each target, but for the inspection as a whole.\n",
    "\n",
    "*Evaluation Metric:* ROC AUC (object — inspection)\n",
    "\n",
    "*Required Deliverables*:\n",
    "- Model Weights: The trained model's weights for reproducibility and further analysis.\n",
    "- Executable Script: A script containing all necessary code to run the model, including data reading, preprocessing steps, model architecture, inference code.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to train a fraud detection model with a simplified target that does not account for cases where two photos in an inspection may capture the same side of the vehicle. For this, we will use a pretrained ResNet18 model and replace its classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarSide(Enum):\n",
    "    FRONT = 0\n",
    "    BACK = 1\n",
    "    LEFT = 2\n",
    "    RIGHT = 3\n",
    "    UNKNOWN = 4\n",
    "    \n",
    "class FraudResolution(Enum):\n",
    "    ALL_GOOD = 0\n",
    "    LACK_OF_PHOTOS = 1\n",
    "    BLURRY_PHOTO = 2\n",
    "    SCREEN_PHOTO = 3\n",
    "    DARK_PHOTO = 4\n",
    "    INCOMPLETE_CAPTURE = 5\n",
    "    \n",
    "class DamageResolution(Enum):\n",
    "    NO_DEFECT = 0\n",
    "    DEFECT = 1\n",
    "    BAD_PHOTO = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_verdict_mapping = {\n",
    "    'ALL_GOOD': 0,\n",
    "    'LACK_OF_PHOTOS': 1,\n",
    "    'BLURRY_PHOTO': 2,\n",
    "    'SCREEN_PHOTO': 3,\n",
    "    'DARK_PHOTO': 4,\n",
    "    'INCOMPLETE_CAPTURE': 5,\n",
    "}\n",
    "\n",
    "description['fraud_label'] = description['fraud_verdict'].map(fraud_verdict_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_verdict_mapping = {\n",
    "    'NO_DEFECT': 0,\n",
    "    'DEFECT': 1,\n",
    "    'BAD_PHOTO': 2\n",
    "}\n",
    "\n",
    "description['damage_label'] = description['damage_verdict'].map(damage_verdict_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_verdict_mapping = {\n",
    "    'ALL_GOOD': 0,\n",
    "    'LACK_OF_PHOTOS': 1,\n",
    "    'BLURRY_PHOTO': 2,\n",
    "    'SCREEN_PHOTO': 3,\n",
    "    'DARK_PHOTO': 4,\n",
    "    'INCOMPLETE_CAPTURE': 5,\n",
    "}\n",
    "\n",
    "description['fraud_label'] = description['fraud_verdict'].map(fraud_verdict_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_side_mapping = {\n",
    "    'front': CarSide.FRONT.value,\n",
    "    'back': CarSide.BACK.value,\n",
    "    'left': CarSide.LEFT.value,\n",
    "    'right': CarSide.RIGHT.value,\n",
    "    'unknown': CarSide.UNKNOWN.value\n",
    "}\n",
    "\n",
    "description['fact_side_label'] = description['fact_side'].map(fact_side_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "description['final_label'] = 1 - ((description['fraud_label'] == 0) & (description['damage_label'] == 0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.0\n",
    "description = description[\n",
    "    (description['fraud_probability'] >= confidence_threshold) &\n",
    "    (description['damage_probability'] >= confidence_threshold)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181805, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_ID = \"vit_mediumd_patch16_reg4_gap_256.sbb_in12k_ft_in1k\"\n",
    "MODEL_ID = \"efficientformer_l1.snap_dist_in1k\"\n",
    "\n",
    "data_config = timm.data.resolve_data_config(timm.get_pretrained_cfg(MODEL_ID).__dict__)\n",
    "TRANSFORMS = timm.data.create_transform(**data_config, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(model_id, is_training):\n",
    "    data_config = timm.data.resolve_data_config({}, model=timm.create_model(model_id, pretrained=True, num_classes=0))\n",
    "    transforms_ = timm.data.create_transform(**data_config, is_training=is_training)\n",
    "    return transforms_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=235, interpolation=bicubic, max_size=None, antialias=True)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    MaybeToTensor()\n",
       "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "import random\n",
    "import imageio\n",
    "\n",
    "class MultiTargetDatasetWithAugs(Dataset):\n",
    "    def __init__(self, img_dir, description, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.description = description.reset_index()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.flip_augmenter = iaa.Fliplr(1.0)\n",
    "        self.noise_augmenters = iaa.OneOf([\n",
    "            iaa.AdditiveGaussianNoise(scale=(1, 15)),  \n",
    "            iaa.AdditiveLaplaceNoise(scale=(5, 15)), \n",
    "            iaa.AdditivePoissonNoise(lam=(1, 15)),\n",
    "            iaa.SaltAndPepper(p=(0.003, 0.005)), \n",
    "            iaa.Salt(p=(0.003, 0.007)),    \n",
    "            iaa.Pepper(p=(0.003, 0.01)),      \n",
    "            iaa.MultiplyElementwise((0.95, 1.05)),      \n",
    "            iaa.Dropout(p=(0.001, 0.005)),    \n",
    "            iaa.JpegCompression(compression=(5, 10))\n",
    "        ])\n",
    "        self.sharpen_augmenter = iaa.Sharpen(alpha=(0.1, 0.5), lightness=(0.75, 2.0))\n",
    "\n",
    "        self.blur_augmenters = iaa.OneOf([\n",
    "            iaa.GaussianBlur(sigma=(2.0, 4.0)),\n",
    "            iaa.MotionBlur(k=(8, 20)),\n",
    "            iaa.MedianBlur(k=(7, 9))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.description)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.description.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        last_aug_type = \"none\"\n",
    "        fraud_label = row['fraud_label']\n",
    "        damage_label = row['damage_label']\n",
    "        fact_side_label = row['fact_side_label']\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            if row['fact_side_label'] in [CarSide.FRONT.value, CarSide.BACK.value, CarSide.UNKNOWN.value]:\n",
    "                image = self.flip_augmenter(image = np.array(image))\n",
    "                image = Image.fromarray(image) \n",
    "            else:\n",
    "                image = self.flip_augmenter(image = np.array(image))\n",
    "                image = Image.fromarray(image) \n",
    "            \n",
    "                if fact_side_label == CarSide.LEFT.value:\n",
    "                    fact_side_label = CarSide.RIGHT.value\n",
    "                else:\n",
    "                    fact_side_label = CarSide.LEFT.value\n",
    "                \n",
    "            last_aug_type = \"flip\"\n",
    "\n",
    "        if random.random() < 0.1:\n",
    "            image = self.noise_augmenters(image = np.array(image))\n",
    "            image = Image.fromarray(image) \n",
    "            last_aug_type = \"noise\"\n",
    "\n",
    "        if random.random() < 0.1 and row['fraud_label'] != 2:\n",
    "            image = self.sharpen_augmenter(image = np.array(image))\n",
    "            image = Image.fromarray(image) \n",
    "            last_aug_type = \"sharpen\"\n",
    "\n",
    "        if random.random() < 0.1 and fraud_label == 0:\n",
    "            image = self.blur_augmenters(image = np.array(image))            \n",
    "            image = Image.fromarray(image)            \n",
    "            fraud_label = fraud_verdict_mapping['BLURRY_PHOTO']    \n",
    "            damage_label = damage_verdict_mapping['BAD_PHOTO']\n",
    "\n",
    "            last_aug_type = \"blur\"\n",
    "\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        final_label = 1 - int((fraud_label == 0) & (damage_label == 0))\n",
    "\n",
    "        data = {\n",
    "            'image': image,\n",
    "            'fraud_label': fraud_label,\n",
    "            'damage_label': damage_label,\n",
    "            'fact_side_label': fact_side_label,\n",
    "            'final_label': final_label,\n",
    "            'pass_id': row['pass_id'],\n",
    "            'plan_side': row['plan_side'],\n",
    "            'last_aug_type' : last_aug_type\n",
    "        }\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTargetDataset(Dataset):\n",
    "    def __init__(self, img_dir, description, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.description = description.reset_index()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.description)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.description.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        data = {\n",
    "            'image': image,\n",
    "            'fraud_label': row['fraud_label'],\n",
    "            'damage_label': row['damage_label'],\n",
    "            'fact_side_label': row['fact_side_label'],\n",
    "            'final_label': row['final_label'],\n",
    "            'pass_id': row['pass_id'],\n",
    "            'plan_side': row['plan_side']\n",
    "        }\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform stratified split based on 'target'\n",
    "train_df, val_df = train_test_split(\n",
    "    description,\n",
    "    test_size=TEST_SIZE,\n",
    "    stratify=description['final_label'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_thresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[\n",
    "    (train_df['fraud_probability'] >= conf_thresh) &\n",
    "    (train_df['damage_probability'] >= conf_thresh)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = MultiTargetDatasetWithAugs(img_dir=PUBLIC_DATA_FOLDER_PATH, description=train_df, transform=TRANSFORMS)\n",
    "val_dataset = MultiTargetDataset(img_dir=PUBLIC_DATA_FOLDER_PATH, description=val_df, transform=TRANSFORMS)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import auroc, f1_score\n",
    "\n",
    "class CarInspectionModel(pl.LightningModule):\n",
    "    def __init__(self, model_id, num_fraud_classes, num_damage_classes, num_fact_side_classes,\n",
    "                 weight_fraud=1.0, weight_damage=1.0, weight_fact_side=1.0, weight_final=1.0,\n",
    "                 learning_rate=1e-3, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Backbone model from timm\n",
    "        self.backbone = timm.create_model(\n",
    "            model_id,\n",
    "            pretrained=True,\n",
    "            num_classes=0\n",
    "        )\n",
    "        num_features = self.backbone.num_features  # Number of features from the backbone\n",
    "\n",
    "        # Activation and dropout layers\n",
    "        self.activation = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Classification heads\n",
    "        self.fraud_classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, num_features),\n",
    "            self.activation,\n",
    "            self.dropout,\n",
    "            nn.Linear(num_features, num_fraud_classes)\n",
    "        )\n",
    "\n",
    "        self.damage_classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, num_features),\n",
    "            self.activation,\n",
    "            self.dropout,\n",
    "            nn.Linear(num_features, num_damage_classes)\n",
    "        )\n",
    "\n",
    "        self.fact_side_classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, num_features),\n",
    "            self.activation,\n",
    "            self.dropout,\n",
    "            nn.Linear(num_features, num_fact_side_classes)\n",
    "        )\n",
    "\n",
    "        # Final binary classification head using intermediate features\n",
    "        self.final_classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, num_features),\n",
    "            self.activation,\n",
    "            self.dropout,\n",
    "            nn.Linear(num_features, 1)\n",
    "        )\n",
    "\n",
    "        # Loss functions\n",
    "        self.fraud_loss_fn = nn.CrossEntropyLoss()\n",
    "        self.damage_loss_fn = nn.CrossEntropyLoss()\n",
    "        self.fact_side_loss_fn = nn.CrossEntropyLoss()\n",
    "        self.final_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Loss weights\n",
    "        self.weight_fraud = weight_fraud\n",
    "        self.weight_damage = weight_damage\n",
    "        self.weight_fact_side = weight_fact_side\n",
    "        self.weight_final = weight_final\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        fraud_logits = self.fraud_classifier(features)\n",
    "        damage_logits = self.damage_classifier(features)\n",
    "        fact_side_logits = self.fact_side_classifier(features)\n",
    "        final_logits = self.final_classifier(features)\n",
    "\n",
    "        return fraud_logits, damage_logits, fact_side_logits, final_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images = batch['image']\n",
    "        fraud_labels = batch['fraud_label']\n",
    "        damage_labels = batch['damage_label']\n",
    "        fact_side_labels = batch['fact_side_label']\n",
    "        final_labels = batch['final_label']\n",
    "\n",
    "        fraud_logits, damage_logits, fact_side_logits, final_logits = self(images)\n",
    "        loss_fraud = self.fraud_loss_fn(fraud_logits, fraud_labels)\n",
    "        loss_damage = self.damage_loss_fn(damage_logits, damage_labels)\n",
    "        loss_fact_side = self.fact_side_loss_fn(fact_side_logits, fact_side_labels)\n",
    "        loss_final = self.final_loss_fn(final_logits.squeeze(), final_labels.float())\n",
    "        total_loss = (self.weight_fraud * loss_fraud +\n",
    "                      self.weight_damage * loss_damage +\n",
    "                      self.weight_fact_side * loss_fact_side +\n",
    "                      self.weight_final * loss_final)\n",
    "\n",
    "        self.log('train_loss', total_loss, prog_bar=True)\n",
    "        self.log('train_loss_fraud', loss_fraud)\n",
    "        self.log('train_loss_damage', loss_damage)\n",
    "        self.log('train_loss_fact_side', loss_fact_side)\n",
    "        self.log('train_loss_final', loss_final)\n",
    "\n",
    "        fraud_preds = torch.argmax(fraud_logits, dim=1)\n",
    "        f1_fraud = f1_score(fraud_preds, fraud_labels, num_classes=fraud_logits.size(1), task=\"multiclass\", average='macro')\n",
    "        self.log('train_f1_fraud', f1_fraud, prog_bar=True)\n",
    "\n",
    "        damage_preds = torch.argmax(damage_logits, dim=1)\n",
    "        f1_damage = f1_score(damage_preds, damage_labels, num_classes=damage_logits.size(1), task=\"multiclass\", average='macro')\n",
    "        self.log('train_f1_damage', f1_damage, prog_bar=True)\n",
    "\n",
    "        fact_side_preds = torch.argmax(fact_side_logits, dim=1)\n",
    "        f1_fact_side = f1_score(fact_side_preds, fact_side_labels, num_classes=fact_side_logits.size(1), task=\"multiclass\", average='macro')\n",
    "        self.log('train_f1_fact_side', f1_fact_side, prog_bar=True)\n",
    "\n",
    "        final_probs = torch.sigmoid(final_logits.squeeze())\n",
    "        auc_final = auroc(final_probs, final_labels.int(), task=\"binary\")\n",
    "        self.log('train_final_auc', auc_final, prog_bar=True)\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images = batch['image']\n",
    "        fraud_labels = batch['fraud_label']\n",
    "        damage_labels = batch['damage_label']\n",
    "        fact_side_labels = batch['fact_side_label']\n",
    "        final_labels = batch['final_label']\n",
    "\n",
    "        fraud_logits, damage_logits, fact_side_logits, final_logits = self(images)\n",
    "        loss_fraud = self.fraud_loss_fn(fraud_logits, fraud_labels)\n",
    "        loss_damage = self.damage_loss_fn(damage_logits, damage_labels)\n",
    "        loss_fact_side = self.fact_side_loss_fn(fact_side_logits, fact_side_labels)\n",
    "        loss_final = self.final_loss_fn(final_logits.squeeze(), final_labels.float())\n",
    "        total_loss = (self.weight_fraud * loss_fraud +\n",
    "                      self.weight_damage * loss_damage +\n",
    "                      self.weight_fact_side * loss_fact_side +\n",
    "                      self.weight_final * loss_final)\n",
    "\n",
    "        self.log('val_loss', total_loss, prog_bar=True)\n",
    "        self.log('val_loss_fraud', loss_fraud)\n",
    "        self.log('val_loss_damage', loss_damage)\n",
    "        self.log('val_loss_fact_side', loss_fact_side)\n",
    "        self.log('val_loss_final', loss_final)\n",
    "\n",
    "        fraud_preds = torch.argmax(fraud_logits, dim=1)\n",
    "        f1_fraud = f1_score(fraud_preds, fraud_labels, num_classes=fraud_logits.size(1), task=\"multiclass\", average='macro')\n",
    "        self.log('val_f1_fraud', f1_fraud, prog_bar=True)\n",
    "\n",
    "        damage_preds = torch.argmax(damage_logits, dim=1)\n",
    "        f1_damage = f1_score(damage_preds, damage_labels, num_classes=damage_logits.size(1), task=\"multiclass\", average='macro')\n",
    "        self.log('val_f1_damage', f1_damage, prog_bar=True)\n",
    "\n",
    "        fact_side_preds = torch.argmax(fact_side_logits, dim=1)\n",
    "        f1_fact_side = f1_score(fact_side_preds, fact_side_labels, num_classes=fact_side_logits.size(1), task=\"multiclass\", average='macro')\n",
    "        self.log('val_f1_fact_side', f1_fact_side, prog_bar=True)\n",
    "\n",
    "        final_probs = torch.sigmoid(final_logits.squeeze())\n",
    "        auc_final = auroc(final_probs, final_labels.int(), task=\"binary\")\n",
    "        self.log('val_final_auc', auc_final, prog_bar=True)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        param_groups = [\n",
    "            {\n",
    "                'params': [p for n, p in self.named_parameters() if not any(nd in n for nd in ['bias', 'LayerNorm.weight'])],\n",
    "                'weight_decay': 1e-4\n",
    "            },\n",
    "            {\n",
    "                'params': [p for n, p in self.named_parameters() if any(nd in n for nd in ['bias', 'LayerNorm.weight'])],\n",
    "                'weight_decay': 0.0\n",
    "            }\n",
    "        ]\n",
    "        optimizer = torch.optim.AdamW(param_groups, lr=self.learning_rate)\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=50, T_mult=1, eta_min=1e-5,\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CarInspectionModel(\n",
    "    model_id=MODEL_ID,\n",
    "    num_fraud_classes=len(fraud_verdict_mapping),\n",
    "    num_damage_classes=len(damage_verdict_mapping),\n",
    "    num_fact_side_classes=len(fact_side_mapping),\n",
    "    weight_fraud=1.0,\n",
    "    weight_damage=1.0,\n",
    "    weight_fact_side=1.0,\n",
    "    weight_final=3.0,\n",
    "    learning_rate=LR,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = MODEL_ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CSVLogger(\"logs_effformer\", name=EXP_NAME, version=f\"test\")\n",
    "logger.log_hyperparams({\"model_id\": {MODEL_ID}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_final_auc',  # Monitor the final ROC AUC\n",
    "    mode='max',\n",
    "    save_top_k=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger=logger,\n",
    "    max_epochs=5,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    log_every_n_steps=100,\n",
    "    val_check_interval=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "script = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(script, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = torch.jit.load('model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: There are only **filename**, **pass_id**, **plan_side** in private data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from utils import get_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, device, fact_side_mapping=fact_side_mapping, side_confidence_threshold=0.7):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    final_predictions = []\n",
    "    pass_ids = []\n",
    "    plan_sides = []\n",
    "    predicted_fact_sides = []\n",
    "    fact_side_confidences = []\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(dataloader):\n",
    "            images = batch['image'].to(device)\n",
    "            batch_pass_ids = batch['pass_id']\n",
    "            batch_plan_sides = batch['plan_side']\n",
    "            \n",
    "            _, _, fact_side_logits, final_logits = model(images)\n",
    "            \n",
    "            final_probs = torch.sigmoid(final_logits.squeeze())\n",
    "            \n",
    "            fact_side_probs = torch.softmax(fact_side_logits, dim=1)\n",
    "            max_probs, fact_side_preds = torch.max(fact_side_probs, dim=1)\n",
    "            fact_side_confidences.extend(max_probs.cpu().numpy())\n",
    "            predicted_fact_sides.extend(fact_side_preds.cpu().numpy())\n",
    "            \n",
    "            final_predictions.extend(final_probs.cpu().numpy())\n",
    "            pass_ids.extend(batch_pass_ids)\n",
    "            plan_sides.extend(batch_plan_sides)\n",
    "    \n",
    "    inverse_fact_side_mapping = {v: k for k, v in fact_side_mapping.items()}\n",
    "    predicted_fact_sides_names = [inverse_fact_side_mapping[label] for label in predicted_fact_sides]\n",
    "    \n",
    "    predictions_df = pd.DataFrame({\n",
    "        'pass_id': pass_ids,\n",
    "        'prediction': final_predictions,\n",
    "        'plan_side': plan_sides,\n",
    "        'predicted_fact_side': predicted_fact_sides_names,\n",
    "        'fact_side_confidence': fact_side_confidences\n",
    "    })\n",
    "    \n",
    "    predictions_df['prediction'] = predictions_df.apply(\n",
    "        lambda row: 1.0 if (row['plan_side'] != row['predicted_fact_side'] and row['fact_side_confidence'] >= side_confidence_threshold) else row['prediction'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = get_predictions(model, val_loader, device, fact_side_mapping=fact_side_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
